{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.signal import find_peaks\n",
    "from pandas import read_excel\n",
    "from pandas import read_csv\n",
    "from time import time \n",
    "import pickle\n",
    "from obspy.signal.detrend import polynomial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from xgboost import XGBRegressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dum_fest(df):\n",
    "    cata = []; fes = read_csv(\"Excels/festivos.csv\")\n",
    "    for j in range(len(fes.index)):\n",
    "            festiveDay = df.loc[(df.year==fes[\"Year\"][j]) & (df.month==fes[\"Month\"][j]) & (df.day==fes[\"Day\"][j])].index.values.tolist()\n",
    "            cata = cata + festiveDay\n",
    "\n",
    "    df['fest'] = np.nan; df.fest = df.fest.fillna(pd.Series(-1, index=cata))\n",
    "    df.fest = df.fest.fillna(0)\n",
    "#     df = df.query(\"fest == 0\")\n",
    "#     df = df.drop(\"fest\", axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lunes   martes-miercoles-jueves   viernes   sabado   domingo\n",
    "def dum_dia(df):\n",
    "    df.día_semana=df.día_semana.apply(lambda x: 1 if x==1 else (2 if x in [2,3,4] else (3 if x==5 else (4 if x==6 else 0))))\n",
    "    df = pd.get_dummies(df, prefix=['d_sm'], columns=['día_semana'])\n",
    "    df = df.drop(\"d_sm_0\", axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dum_seas(df):\n",
    "    df['seas'] = np.nan\n",
    "    pr = df.query('day == 21 and month ==3').index\n",
    "    vr = df.query('day == 21 and month == 6').index\n",
    "    ot = df.query('day == 21 and month == 9').index\n",
    "    inv= df.query('day == 21 and month == 12').index\n",
    "\n",
    "    df.seas = df.seas.fillna(pd.Series(0, index=pr))\n",
    "    df.seas = df.seas.fillna(pd.Series(1, index=vr))\n",
    "    df.seas = df.seas.fillna(pd.Series(2, index=ot))\n",
    "    df.seas = df.seas.fillna(pd.Series(3, index=inv))\n",
    "\n",
    "    df.seas = df.seas.fillna(method= 'ffill')\n",
    "    df.seas = df.seas.fillna(method= 'bfill')\n",
    "\n",
    "    df = pd.get_dummies(df, prefix=['s_s'], columns=['seas'])\n",
    "    df = df.drop(\"s_s_3.0\", axis = 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Enero, Febrero, Marzo, Abril, Mayo, Junio, Julio, Agosto, Septiembre, Octubre, Diciembre\n",
    "def dum_mensual(df):\n",
    "    df = pd.get_dummies(df, prefix=['mon'], columns=['month'])\n",
    "    df = df.drop(\"mon_12\", axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm1(i):\n",
    "    df = pd.read_pickle(\"dflimpios.pkl\")\n",
    "    if i==0:\n",
    "        df = dum_fest(df)\n",
    "    if i==1:\n",
    "        df = dum_dia(df)\n",
    "    if i==2:\n",
    "        df = dum_seas(df)\n",
    "    if i==3:\n",
    "        df = dum_mensual(df)\n",
    "    if i==4:\n",
    "        df = dum_mensual(dum_seas(dum_dia(dum_fest(df)))) \n",
    "    return df\n",
    "fm1(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sonas(): \n",
    "    return [\"zona_{}\".format(i+1) for i in range(26)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones para regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zon_hor(h,z):\n",
    "    hora_n = df.query('hora == {}'.format(h))\n",
    "    zon_n = hora_n['{}'.format(z)]\n",
    "#     zon_n = polynomial(zon_n, order=2)\n",
    "    return zon_n.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dums(h):\n",
    "    dem = ['hora',]# 'year', 'month']\n",
    "    zro =  sonas() #+dem\n",
    "    sin_zonas = df[df[\"hora\"]==h]\n",
    "    sin_zonas=sin_zonas.reset_index()\n",
    "    sin_zonas = sin_zonas.drop(zro,  axis=1)\n",
    "    sin_zonas = sin_zonas.drop('index', axis=1)\n",
    "    return  sin_zonas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_pts(h, z, armon):\n",
    "    from  scipy import signal\n",
    "    x = get_zon_hor(1, \"zona_1\")\n",
    "    f, asd = signal.periodogram(x, fs=1)\n",
    "    peaks, _ = find_peaks(asd, height=0)\n",
    "    altura = _['peak_heights']\n",
    "    fan = 1/(f[peaks])\n",
    "    app = pd.DataFrame(altura, fan, columns=[\"altura_pk\"]).sort_values(by=\"altura_pk\",ascending=False).head(armon).iloc[armon-1:]\n",
    "    return app;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sc_coef(h, z, armon):\n",
    "    X = pd.DataFrame()\n",
    "    t = np.arange(len(df[df[\"hora\"]==h]))\n",
    "    X[\"te\"] = t \n",
    "    p = get_max_pts(h, z, armon)\n",
    "    for i  in p.index:\n",
    "        X[\"{}_sen\".format(i)] = (np.sin((t*2*np.pi)/i))\n",
    "        X[\"{}_cos\".format(i)] = (np.cos((t*2*np.pi)/i))\n",
    "    X[\"unos\"] = 1\n",
    "    X = X.drop(\"te\", axis = 1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kron_conv(h, z, armon):\n",
    "    dm1 = get_dums(h); dm2 = get_sc_coef(h, z, armon)\n",
    "    d3 = pd.DataFrame(); kron = pd.DataFrame()\n",
    "    for i in dm2.columns:\n",
    "        d3 = dm1.multiply(dm2[f\"{i}\"], axis=\"index\")\n",
    "        d3.columns = [f\"{j}_{i}\" for j in dm1.columns]\n",
    "        kron = pd.concat([kron, d3], axis = 1)\n",
    "    X = kron.reset_index()\n",
    "    X2 = pd.concat([X, dm1, dm2], sort = False, axis=1)\n",
    "    X2 = X2.drop('index', axis = 1)\n",
    "    X2 = X2.drop('unos', axis = 1)\n",
    "    return X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    ma = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_split_sick(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/len(y), shuffle = False)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_split_xgb(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = False)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 1/len(y_test), shuffle = False)\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llamar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file = open('Excels/mapes_1dia.pkl', 'rb')\n",
    "EAD = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "ED = EAD[\"mape\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg = time()\n",
    "for z in range(1, 27):\n",
    "    EM = pd.DataFrame()\n",
    "    EM[[\"model\", \"armon\", \"dli\"]] = ED[f\"zona_{z}\"].idxmin(axis = 1).str.split('_', expand=True)\n",
    "    EM[[\"armon\", \"dli\"]] = EM[[\"armon\", \"dli\"]].astype(int, errors = 'ignore')\n",
    "    EM = EM.replace(['Sck', 'XGB','AR'],[1,2, 3])\n",
    "\n",
    "    for h, a, armon, datos in zip(EM.index, EM[\"model\"], EM[\"armon\"], EM[\"dli\"]):  \n",
    "        \n",
    "        if armon and datos == None:\n",
    "            y = np.array(get_zon_hor(h,f\"zona_{z}\"))\n",
    "            y_train, y_test = train_test_split(y, test_size = 1/len(y), shuffle = False)\n",
    "            regresar = AR(y_train).fit()\n",
    "            # Guradar modelo regresar\n",
    "            output = open(f'Modelos/Zona{z}_hora{h}_AR.pkl', 'wb')\n",
    "            pickle.dump(regresar, output)\n",
    "            output.close()\n",
    "            \n",
    "        if a == 1:\n",
    "            df = fm1(datos)\n",
    "            y = np.array(get_zon_hor(h,f\"zona_{z}\"))\n",
    "            X = kron_conv(h,f\"zona_{z}\", armon)\n",
    "            X_tr, X_te, y_tr, y_te = get_train_split_sick(X, y)\n",
    "            regress = LinearRegression(n_jobs = -1).fit(X_tr, y_tr)\n",
    "            # Guardar modelo regress\n",
    "            output = open(f'Modelos/Zona{z}_hora{h}.pkl', 'wb')\n",
    "            pickle.dump(regress, output)\n",
    "            output.close()\n",
    "            \n",
    "        if a == 2:\n",
    "            df = fm1(datos)\n",
    "            y = np.array(get_zon_hor(h,f\"zona_{z}\"))\n",
    "            X = kron_conv(h,f\"zona_{z}\", armon)\n",
    "            X_train, X_test, X_val, y_train, y_test, y_val = get_train_split_xgb(X, y)\n",
    "            regress2 = XGBRegressor(objective ='reg:squarederror', n_jobs=-1, max_depth=3, learning_rate=1.5, n_estimators=5)\n",
    "            regress2.fit(X_train, y_train, eval_set=[(X,y),(X_val,y_val)], verbose=0 , early_stopping_rounds=50)\n",
    "            #Guardar modelo regress2\n",
    "            output = open(f'Modelos/Zona{z}_hora{h}.pkl', 'wb')\n",
    "            pickle.dump(regress2, output)\n",
    "            output.close()\n",
    "end = time()\n",
    "end - beg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress = {}\n",
    "for z in range(1, 27):\n",
    "    EM = pd.DataFrame()\n",
    "    EM[[\"model\", \"armon\", \"dli\"]] = ED[f\"zona_{z}\"].idxmin(axis = 1).str.split('_', expand=True)\n",
    "    EM[[\"armon\", \"dli\"]] = EM[[\"armon\", \"dli\"]].astype(int, errors = 'ignore')\n",
    "    EM = EM.replace(['Sck', 'XGB','AR'],[1,2, 3])\n",
    "\n",
    "    for h, a, armon, datos in zip(EM.index, EM[\"model\"], EM[\"armon\"], EM[\"dli\"]):  \n",
    "        \n",
    "        if armon and datos == None:\n",
    "            y = np.array(get_zon_hor(h,f\"zona_{z}\"))\n",
    "            y_train, y_test = train_test_split(y, test_size = 1/len(y), shuffle = False)\n",
    "            regress[f\"zona_{z}_hora_{h}_arm_{armon}_dll_{datos}_AR\"] = AR(y_train).fit()\n",
    "            # Guradar modelo regresar\n",
    "            \n",
    "        if a == 1:\n",
    "            df = fm1(datos)\n",
    "            y = np.array(get_zon_hor(h,f\"zona_{z}\"))\n",
    "            X = kron_conv(h,f\"zona_{z}\", armon)\n",
    "            X_tr, X_te, y_tr, y_te = get_train_split_sick(X, y)\n",
    "            regress[f\"zona_{z}_hora_{h}_arm_{armon}_dll_{datos}_sck\"] = LinearRegression(n_jobs = -1).fit(X_tr, y_tr)\n",
    "            # Guardar modelo regress\n",
    "            \n",
    "        if a == 2:\n",
    "            df = fm1(datos)\n",
    "            y = np.array(get_zon_hor(h,f\"zona_{z}\"))\n",
    "            X = kron_conv(h, f\"zona_{z}\", armon)\n",
    "            X_train, X_test, X_val, y_train, y_test, y_val = get_train_split_xgb(X, y)\n",
    "            regress[f\"zona_{z}_hora_{h}_arm_{armon}_dll_{datos}_XGB\"] = XGBRegressor(objective ='reg:squarederror', n_jobs=-1, max_depth=3, learning_rate=1.5, n_estimators=5)\n",
    "            regress[f\"zona_{z}_hora_{h}_arm_{armon}_dll_{datos}_XGB\"].fit(X_train, y_train, eval_set=[(X,y),(X_val,y_val)], verbose=0 , early_stopping_rounds=50)\n",
    "            #Guardar modelo regress\n",
    "            \n",
    "output = open(f'Modelos/modelos.pkl', 'wb')\n",
    "pickle.dump(regress, output)\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
